Below are the **prerequisite steps that come *before* the “tightened Phase 1 plan”** you pasted. Think of this as **Phase 0 (Pre-flight)**—the stuff that prevents Week 1 from turning into thrash.

---

## Phase 0 (Days 0–3): Pre-flight decisions + proof the data layer is real

### 0.1 Lock the meaning of “Canonical Key”

You had a mix-up earlier, so make this explicit in your docs:

* `NOTION_API_KEY` = secret token for Notion
* `NOTION_DATABASE_ID=2e071fcdd2d880608c54df9679358bcb` = your Venture Pipeline DB
* `"Canonical Key"` = a **Notion property** used to dedupe companies (not an API key)

**Outcome:** everyone uses the same vocabulary before building anything.

---

### 0.2 Pick the deployment target (so architecture doesn’t wobble)

Make a decision now because it affects auth, env vars, and persistence:

**Recommended default:** **Render (or Fly) for API + persistent disk**

* You need persistence for `signals.db` and likely a second DB (`app.db`).

**If you insist on Vercel:** do **Vercel frontend + Render/Fly API + DB** (still need persistence somewhere).

**Outcome:** a single sentence in the README like:

> “Phase 1 deploy: Render (API + persistent disk), frontend served by (Render|Vercel).”

---

### 0.3 Create a minimal “prod-like” env contract (even for local dev)

Create `.env.example` (even if you don’t commit `.env`):

```bash
# Notion
NOTION_API_KEY=secret_xxx
NOTION_DATABASE_ID=2e071fcdd2d880608c54df9679358bcb

# Local DBs
SIGNALS_DB_PATH=signals.db
APP_DB_PATH=app.db

# API/Auth (placeholders for Phase 1)
JWT_ISSUER=
JWT_AUDIENCE=
JWT_PUBLIC_KEY=
```

**Outcome:** your jobs + API can run locally with the same contract you’ll use in staging.

---

## Phase 0 (Day 1): Confirm the Notion schema *programmatically*

### 0.4 Verify Notion property types (don’t guess)

You said you can’t be sure if “Founder LinkedIn” is always a URL. Great—verify it once.

**Option A: curl (fastest)**

```bash
curl -s \
  -H "Authorization: Bearer $NOTION_API_KEY" \
  -H "Notion-Version: 2022-06-28" \
  "https://api.notion.com/v1/databases/$NOTION_DATABASE_ID" \
  | python -c "import sys, json; d=json.load(sys.stdin); 
props=d.get('properties',{}); 
print('Founder LinkedIn type:', props.get('Founder LinkedIn',{}).get('type'));
print('Founder type:', props.get('Founder',{}).get('type'));
print('Canonical Key type:', props.get('Canonical Key',{}).get('type'))"
```

**What you want to see**

* `Founder LinkedIn type: url`
* `Canonical Key type:` usually `rich_text` (or similar)
* `Founder type:` commonly `rich_text`

**Outcome:** you know whether you must handle “Founder LinkedIn” as URL-only, or URL + rich_text fallback.

---

## Phase 0 (Day 1–2): Decide the data-flow (Notion → local → web app)

### 0.5 Decide: Live Notion reads vs local sync

For Phase 1, pick **local sync**.

**Rule:** the web app should never depend on live Notion calls for page rendering.
Notion becomes an upstream system; your app reads local DBs.

**Outcome:** this unlocks fast UI and avoids rate-limit/latency UX.

---

### 0.6 Decide how founders relate to companies (important for network later)

Right now your design choice is:

**Option 1 (fast MVP):** one founder ↔ one company (skip conflicts)

* If the same LinkedIn appears on multiple companies, you **skip** or **log conflict**.

**Option 2 (correct model):** add a join table now

* `founders` = identity (linkedin key)
* `founder_company_links` = many-to-many (founder ↔ company)

**If you want “network intelligence” to be credible, pick Option 2.**
If you want speed and can tolerate edge cases, pick Option 1 and defer.

**Outcome:** prevents silent overwrites and confusing founder displays later.

---

## Phase 0 (Day 2): Implement the Notion → FounderStore sync job

### 0.7 Implement `workflows/founder_sync.py` (the skeleton you asked for)

This is the job that:

* queries Notion DB by pipeline statuses
* extracts company canonical key (or builds from website/name when missing)
* extracts LinkedIn URLs (supports URL or pasted text)
* normalizes to a stable `founder_key = linkedin:<slug>`
* upserts into your local store
* **skips conflicts by default** unless you explicitly allow relinking

**Outcome:** you now have canonical founder keys available locally for the web app.

### 0.8 Run it in dry-run mode + produce a sync report

Run:

```bash
python -m workflows.founder_sync --db-path signals.db --dry-run --verbose
```

Then real:

```bash
python -m workflows.founder_sync --db-path signals.db
```

**Outcome:** you have hard numbers on:

* how many founders found
* how many LinkedIn URLs valid
* how many conflicts exist
* how many companies lack canonical keys

That tells you whether Week 5–6 “Network” stays in-scope or must be slimmed.

---

## Phase 0 (Day 3): Prove the web app can rely on this data

### 0.9 Add two “smoke endpoints” in your future API contract (even before UI)

Before you build the UI, prove you can serve the data:

* `GET /api/v1/companies?limit=5`
* `GET /api/v1/companies/{id}/founders`

**Outcome:** you validate the full chain:
Notion → sync job → local DB → API payload shape.

---

## Phase 0 Definition of Done (what must be true before Week 1 starts)

You’re ready to begin the “tightened Phase 1 plan” only when:

1. Deployment target selected (Render/Fly vs split Vercel)
2. Notion schema verified (Founder LinkedIn type confirmed)
3. Env contract exists (`.env.example`)
4. Founder sync job runs end-to-end and outputs a summary report
5. Conflict policy chosen (skip vs join table)
6. Two smoke endpoints return data from the local store

---

If you want, I can also rewrite your Week 1–2 table to explicitly include these as **Task 0.1–0.9** (so the plan starts with pre-flight instead of assuming it).
